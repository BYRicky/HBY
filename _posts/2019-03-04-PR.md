---
layout: post
title: 'Perceptron classifier'
tags: ["matlab"]
---
(To be continued....)
Here is an approach to implement simple perception classifier. I will show you guys the entire steps for this implementation.

First, we choose the Iris dataset. This dataset contains 3 classes of 50 instances each, where each class refers to a type of Iris plant. The first two classes are linearly separable from each other, whereas the last class is not linearly separable. With the limitation of this classifier, we only take the first two classes. The following d steps...

**Step 1: Load dataset.** <br>
In matlab, we use `textread` to load the dataset with text format. In this dataset, there are four attributes except for the class name and each attribute is separated by comma. Note that in `textread`, the second parameter is the data type of the dataset (In Iris dataset, the first four features are floating number and the last one is the string), and the fourth one is the delimiter used in the dataset. As the result, we can write the followiong code.
~~~ js
[atrb1,atrb2,atrb3,atrb4,className]=textread(filename,'%f%f%f%f%s','delimiter,',');
~~~

**Step 2: Split training data and testing data.** <br>
Assume that we have 100 instances, and serve 90 samples as training data. The straightforward way is to take the first 90 instances for training and the rest ones for testing. However, it cannot gurantee that these two subsets have similar distributions. In matlab, there is a built-in function `cvpartition`; it gives an systemical way to split training and testing data.
~~~ 
cv=cvpartition(className,'KFold', k);
~~~

**Step 3: Feature space.** <br>
We want to see the 
~~~ js
Tuple={atrb1,atrb2,atrb3,atrb4}
Title={'Speal.Length','Sepal.Width','Petal.Length','Petal.Width'};
for i=1:atrb
  for j=1:atrb
    if(i==j); continue; end
    subplot(atrb,atrb,(i-1)*atrb+j);
    gscatter(Tuple(:,i),Tuple(:,j),className,'rg','.',8);
    xlabel(Title(i)); ylabel(Title(j));
    legend('off');
 end
end
~~~
