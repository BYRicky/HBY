---
layout: post
title: '(Not finished) Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects' 
subtitle: 'Authors: Martin Runz and Lourdes Agapito'
tags: ["3DMatch"]

---
- surfel = point cloud ?


## Co-Fusion
- a live RGB-D SLAM system that processes each new frame in real time
- maintains two sets of object models: **active** and **inactive** models
  - active: are currently visible in the live frame
  - inactive: were once visible, and their geometry is known, but currently out of view
- the scene is initialized to contain a single active model
- do Tracking, Segementation, Fusion when fused 3D model of the background and the camera pose are **stable**
  - Tracking: track the 6DoF rigid pose of each active model in the current frame
  
  - Segmentation: based on motion or semantic labels
    - motion segmentation:  using fully connected Conditional Random Field (CRF) and optimization which is followed by the extraction of connected compoenents in the segmented image.
    - multi-class image segmentation: class labels obtained by deep learning
    
  - Fuion: ...
- Note: Tracking and fusion are run on the GPU, while segmentation is run on CPU
  - Engry: for each active model Mm, the goal is to minimize the cost function that combines point-to-plane ICP alignment and a photometric color term
  - Geometry term: 
  
  
  
---

## Tracking active models
- input: input frame at time t and for each active model Mm


---
