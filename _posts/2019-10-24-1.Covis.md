---
layout: post
title: 'Co-Fusion: Real-time Segmentation, Tracking and Fusion of Multiple Objects' 
subtitle: 'Authors: Martin Runz and Lourdes Agapito'
tags: ["3DMatch"]

---

## Co-Fusion
- a live RGB-D SLAM system that processes each new frame in real time
- maintains two sets of object models: **active** and **inactive** models
  - active: are currently visible in the live frame
  - inactive: were once visible, and their geometry is known, but currently out of view
- the scene is initialized to contain a single active model
- do Tracking, Segementation, Fusion when fused 3D model of the background and the camera pose are **stable**
  - Tracking: track the 6DoF rigid pose of each active model in the current frame
  
  - Segmentation: based on motion or semantic labels
    - motion segmentation:  using fully connected Conditional Random Field (CRF) and optimization which is followed by the extraction of connected compoenents in the segmented image.
    - multi-class image segmentation: class labels obtained by deep learning
    
  - Fuion: ...
- Note: Tracking and fusion are run on the GPU, while segmentation is run on CPU

---

## Learning From Reconstructions


---
