---
layout: post
title: 'Point Cloud Registraion'
tags: ["Point Cloud Registration"]

---

## Classical
- ICP (Iterative Closest Point)
  - local method
  - heavily rely on inital estimate, and then refine iteratively
  
- Variant ICP
  - Generalized-ICP, RSS, 2009
  - Trimmed-ICP, IMAVIS, 2005
  
- Variant ICP (global method)
  - multiple restarts (Registration of range data using a hybrid simulated annealing and iterative closest point algorithm, ICRA, 2000)
  - graph optimization (Globally consistent registration of terrestrial laser scans via graph optimization, ISPRS Journal of Photogrammetry and Remote
Sensing, 2015)
  - branch-and-bound (Gogma: Globally-optimal gaussian mixture alignment, CVPR, 2016)
  
## Probabilistic based
- Correlation based
  - Robust point set registration using gaussian mixture models, PAMI, 2011
  - A correlation-based approach to robust point set registration, ECCV, 2004 
  
- EM based
  - CPD (Coherent Point Drift), PAMI, 2010
  - JRMPC (Joint Registration of Multiple Point Clouds), ECCV, 2014
  - DARE (Density Adaptive Point Set Registration), CVPR, 2018
    - Desnity adaptive version of JRMPC
    - The **density variation is problematic for standard ML-based approaches** since each 3D-point corresponds to an observation with equal weight. Thus, the registration focuses on regions with high point densities, while neglecting sparse regions

## Key-Point based
- FPFH (Fast Point Feature Histogram), ICRA, 2009

## Plane based
- Efficient and accurate registration of point clouds with plane to plane correspondences, ICCV Workshop, 2017

## Learning based
- PointNetLK, CVPR, 2019
- 3D point cloud registration for localization using a deep neural network auto-encoder, CVPR, 2017

----

## handcrafted descriptor
  - USC, SHOT, ...
  
## LEARNING BASED  
### learning-based descriptor
  - stablish the pointwise candidate correspondences in combination with a RANSAC-like robust estimator or geometric hashing.
  - patch-based networks
    - `3DMatch`: voxelizes the region around each keypoint and compute descriptors with a 3DCNN trained using a contrastive loss

    - `CGF`: map 3D oriented histograms to a low-dimensional feature space using multi-layer perceptrons

    - `3DSmoothNet`:employs a voxelized smoothed density value (SDV) representation for descriptor learning. predicts a patch-wise detection score, whereas only limited spatial context is considered and a dense inference for the entire point cloud is not applicable in practice. 

    - `PpfNet, PpfFoldNet`:since voxelization results is in a loss of quality, they uses a PointNet architecture to learn features directly from raw point clouds. PpfFoldNet adopts folding-based autoencoder to learn a local descriptor

  - fully-convolutional networks
    - `FCGF`: compared with 3DMatch, CGF, PPFFoldNet, PPFNet, 3DSmoothNet, it has higer receptive field prior works extract a small 3D patch or a set of points and map it to a low-dimensional space. It uses sparse convolution proposed in [1] to extract feature descriptors and achieves rotation invariance by simple data augmentation.

### learning-based detector
  - USIP
  
### learning-based detector and descriptor
  - `3DFeatNet`: predicts a patch-wise detection score, whereas only limited spatial context is considered and a dense inference for the entire point cloud is not applicable in practice.

  - `D3Feat`: draw inspiration from D2-Net in 2D domain for a joint learning of a feature detector and descriptor
  
### learning-based registration
 - `PointNetLk`: **X** compute a global representation of
each point cloud, then optimizes the transforms to minimize
the distances between the global descriptors in an iterative
fashion analogous to the Lucas-Kanade algorithm. It cannot handle 
partial-to-partial point cloud registration

 - `PCRNet`: **X** replace the Lucas-Kanade step in PointNetLK with a deep network.
 
 - `DCP`: **V** extracts features for each point to compute a soft matching 
 between the point clouds before using a differentiable SVD module to 
 extract the rigid transformation. It cannot handle partialto-partial 
 point cloud registration. It utilize a transformer network to 
 incorporate global and inter point cloud information when 
 computing the feature representations
 
 - `PR-Net`: **V** incorporates keypoint detection to handle partial visibility.
 It can handle partialto-partial point cloud registration.
 
 - `RPM-Net`: **V** It is based on the RPM framework. To handle outliers and 
 partial visibility with the use of Sinkhorn normalization from RPM. 
 Spatial distances in RPM are replaced with learned hybrid feature distances.
 
 - `3DReg`: **X** focus on inlier/outlier dealing.
 
 - `DGR`: **V** It can handle partialto-partial point cloud registration.
  
