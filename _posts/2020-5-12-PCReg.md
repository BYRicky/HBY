---
layout: post
title: 'Point Cloud Registraion'
tags: ["Point Cloud Registration"]

---

## NON-LEARNING BASED
### Classical
- `ICP`: local method. heavily rely on inital estimate, and then refine iteratively.
  
- `Variant ICP (local)`: Generalized-ICP (RSS, 2009), Trimmed-ICP (IMAVIS, 2005)
  
- `Variant ICP (global)`: multiple restarts, graph optimization, branch-and-bound
  - multiple restarts (Registration of range data using a hybrid simulated annealing and iterative closest point algorithm, ICRA, 2000)
  - graph optimization (Globally consistent registration of terrestrial laser scans via graph optimization, ISPRS Journal of Photogrammetry and Remote Sensing, 2015)
  - branch-and-bound (Gogma: Globally-optimal gaussian mixture alignment, CVPR, 2016)
  
### Probabilistic
- Correlation based
  - A correlation-based approach to robust point set registration, ECCV, 2004 
  - [[code]](https://github.com/neka-nat/probreg) `GMMReg (PAMI'11)`:
    It minimizes the distance of two probabilistic distributions.

- EM based
  - [[code]](https://github.com/neka-nat/probreg) `CPD (PAMI'10)`: 
  It assumes the observation points (fixed) are independently distributed 
  according to a GMM introduced by model points (moving).

  - [[code]](https://team.inria.fr/perception/research/jrmpc/) `JRMPC (ECCV'14)`
   
  - [[code]](https://github.com/neka-nat/probreg) 
  `GMMTree (ECCV'18)`, `FilterReg (CVPR'19)`: 
  It builds a GMM rep-resentation of the observation points (fixed).
  
  - [[code]](https://github.com/felja633/DARE) `DARE (CVPR'18)`: density adatpive + JRMPC
    - The **density variation is problematic for standard ML-based approaches** since each 3D-point corresponds to an observation with equal weight. Thus, the registration focuses on regions with high point densities, while neglecting sparse regions

### Randomized
  - [[code]](https://github.com/intellhave/SDRSAC) `SDRSAC (CVPR'19)`, `RANSAC`

### handcrafted descriptor
  - pfh, fpfh, USC, SHOT,spin image...

---

## LEARNING BASED  
### descriptor
  - stablish the pointwise candidate correspondences in combination with a RANSAC-like robust estimator or geometric hashing.
  - patch-based networks
    - [[code]](https://github.com/andyzeng/3dmatch-toolbox) `3DMatch (CVPR'17)`: 
    It voxelizes the region around each keypoint and 
    compute descriptors with a 3DCNN trained using a contrastive loss.

    - [[code]](https://github.com/marckhoury/CGF) `CGF (ICCV'17)`: 
    It maps 3D oriented histograms to a low-dimensional feature space using multi-layer perceptrons.

    - `PpfNet (CVPR'18)`, [[code]](https://github.com/XuyangBai/PPF-FoldNet) `PpfFoldNet (ECCV'18)`: 
    Since voxelization results is in a loss of quality, they uses a PointNet architecture 
    to learn features directly from raw point clouds. 
    PpfFoldNet adopts folding-based autoencoder to learn a local descriptor.
    Evaluation on 3DMatch dataset.

    - [[code]](https://github.com/zgojcic/3DSmoothNet) `3DSmoothNet (CVPR'19)`: 
    It employs a voxelized smoothed density value (SDV) representation for descriptor learning. 
    It predicts a patch-wise detection score, whereas only limited spatial context is considered 
    and a dense inference for the entire point cloud is not applicable in practice.
    Evaluation on 3DMatch, ETH dataset.

  - fully-convolutional networks
    - [[code]](https://github.com/chrischoy/FCGF) `FCGF (ICCV'19)`: 
    Compared with 3DMatch, CGF, PPFFoldNet, PPFNet, 3DSmoothNet, 
    it has higer receptive field prior works extract a small 3D patch or 
    a set of points and map it to a low-dimensional space. 
    It uses sparse convolution proposed in [1] to extract feature descriptors 
    and achieves rotation invariance by simple data augmentation.
    Evaluation on 3DMatch, KITTI dataset.

### detector
  - [[code]](https://github.com/lijx10/USIP) `USIP (ICCV'19)`
  
### detector and descriptor
  - [[code]](https://github.com/yewzijian/3DFeatNet) `3DFeatNet (ECCV'18)`: 
  predicts a patch-wise detection score, whereas only limited spatial context is considered 
  and a dense inference for the entire point cloud is not applicable in practice.
  Evaluation on Oxford RobotCar, KITTI, and ETH dataset.

  - [[code]](https://github.com/XuyangBai/D3Feat) `D3Feat (CVPR'20)`: 
  draw inspiration from D2-Net in 2D domain for a joint learning of a feature detector and descriptor
  Evaluation on 3DMatch, KITTI, and ETH dataset.
  
### registration
 - [[code]](https://github.com/hmgoforth/PointNetLK) `PointNetLK (CVPR'19)`: **X**
 It is designed to be **iterative**.
 It combines PointNet and image alignment method Lucas-Kanade algorithm. 
 It computes a global representation of each point cloud,
 then optimizes the transforms to minimize the distances between
 the global descriptors in an iterative fashion analogous to the LK algorithm.
 The use of LK produces good generalizability to 
 shapes unseen in training, but is not robust to noise.
 Evaluation on [ModelNet40](https://modelnet.cs.princeton.edu/).
 
 - [[code]](https://github.com/vinits5/pcrnet) `PCRNet (ICCV'19)`: **X**
 It is designed to be **iterative**.
 It replaces the LK step in PointNetLK with a deep network.
 Evaluation on [ModelNet40](https://modelnet.cs.princeton.edu/).
 
 - [[code]](https://github.com/WangYueFt/dcp) `DCP (ICCV'19)`: **V** 
 It is **not iterative**, but can be improved by ICP.
 It extracts features for each point to compute a soft matching 
 between the point clouds before using a differentiable SVD module to 
 extract the rigid transformation.  
 It utilize a transformer network to 
 incorporate global and inter point cloud information when 
 computing the feature representations.
 Evaluation on [ModelNet40](https://modelnet.cs.princeton.edu/).
 
 - [[code]](https://github.com/WangYueFt/prnet) `PR-Net (NIPS'19)` : **V** 
 It is designed to be **iterative**.
 It incorporates **keypoint detection** to handle partial visibility.
 It can handle partial-to-partial point cloud registration, and outperform DCP and PointNetLK.
 (performance on partial-to-partial point cloud registration: PR-Net > DCP > PointNetLK)
 Evaluation on [ModelNet40](https://modelnet.cs.princeton.edu/)
 and [The Stanford 3D Scanning Repository](http://graphics.stanford.edu/data/3Dscanrep/)
 
 -  [[code]](https://github.com/yewzijian/RPMNet) `RPM-Net (CVPR'20)`: **V** 
 It is designed to be **iterative**.
 It is based on the RPM (New algorithms for 2D and 3D
 point matching: pose estimation and correspondence, PR'98) framework. 
 To handle outliers and  partial visibility with the use of Sinkhorn normalization from RPM. 
 Spatial distances in RPM are replaced with learned hybrid feature distances.
 It can well handle partial-to-partial point cloud registration, and outperform DCP, PointNetLK, and PR-Net.
 (performance on partial-to-partial point cloud registration: RPM-Net >> PR-Net > DCP > PointNetLK)
 Evaluation on [ModelNet40](https://modelnet.cs.princeton.edu/).
 
 - [[code]](https://github.com/3DVisionISR/3DRegNet) `3DReg (CVPR'20)`: **X** 
 It solves the outlier rejection given 3D point correspondences.
 Evaluation on **[SUN3D datset](http://sun3d.cs.princeton.edu/) which is reconstrcuted by SfM.** 
 
 
 - [[code]](https://github.com/chrischoy/DeepGlobalRegistration) `DGR (CVPR'20)`: **V** 
 It outperforms DCP and PointNetLK.
 Evaluation on [3DMatch dataset](http://3dmatch.cs.princeton.edu/), 
 [ICL-NUIM Indoor](http://redwood-data.org/indoor/dataset.html), LiDAR RGB-D dataset, Stanford RGB-D dataset
  
